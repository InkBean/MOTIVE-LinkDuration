{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(os.getcwd())\n",
    "PATH = os.getcwd()\n",
    "PATH = PATH + \"/NGSIM.csv\" # this is the original csv file that you want to extract contact duration from\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH, encoding='utf-8', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('Global_Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = df.shape[0]\n",
    "num_features = df.shape[1]\n",
    "print(\"number of samples = \" + str(num_samples))\n",
    "print(\"number of features = \" + str(num_features))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "\n",
    "Big_dictionary = {} # initialize a dictionary that stores all states of links\n",
    "\n",
    "for i in range(num_samples):\n",
    "    \n",
    "    time_holder = data[i][3]\n",
    "    links_now = {}\n",
    "    \n",
    "    #if i > 2000:  # number of rows we want to process\n",
    "        #break\n",
    "    \n",
    "    small_dictionary = {} # stores the links at this point in time(time_holder)\n",
    "    \n",
    "    while data[j][3] == time_holder : # current vehicle \n",
    "        next_vehicle = j + 1 # check the vehicles below it\n",
    "        if next_vehicle >= num_samples:\n",
    "            break\n",
    "                    \n",
    "        while data[next_vehicle][3] == time_holder:\n",
    "            # get relative location, and convert from feet to meters\n",
    "            relative_location = [(data[j][6] - data[next_vehicle][6])/3.28,(data[j][7] - data[next_vehicle][7])/ 3.28]\n",
    "            relative_distance = np.linalg.norm(relative_location)\n",
    "                       \n",
    "            if relative_distance <= 100:  # in the range of 50 meters\n",
    "                \n",
    "                vehicle_pair = [data[j][1], data[next_vehicle][0]] \n",
    "                a = data[j][0:num_features].tolist()\n",
    "                b = data[next_vehicle][1:num_features].tolist()\n",
    "                a.extend(b)\n",
    "                link_features = a                \n",
    "                vehicle_pair = tuple(vehicle_pair) \n",
    "                \n",
    "                small_dictionary.update({vehicle_pair:link_features})                \n",
    "                                        \n",
    "            next_vehicle = next_vehicle + 1\n",
    "            if next_vehicle >= num_samples:\n",
    "                break\n",
    "        \n",
    "        j = j + 1\n",
    "        if j % 100000 == 0:\n",
    "            print(\"This is the \" + str(j) + \"th row\") \n",
    "            # this helps to visualize the progress of processing/how much we've done\n",
    "          \n",
    "    if len(small_dictionary.keys()) != 0:\n",
    "        Big_dictionary.update({time_holder:small_dictionary})\n",
    "                                \n",
    "    i = j\n",
    "\n",
    "print(\"now we have the big dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_links = {} # list that stores all the links that exist at time_current\n",
    "\n",
    "contact_info = [] # list that stores all the data points with contact duration. \n",
    "\n",
    "for time_current, linkinfo_current in Big_dictionary.items(): \n",
    "    # starting from the second key-value pair, key is time, value is dic of link info\n",
    "    #iterate through time\n",
    "                \n",
    "    e_cpy = existing_links.copy() # to avoid RuntimeError: dictionary changed size during iteration\n",
    "    \n",
    "\n",
    "    # iterate through existing links by time, to check if it ends at this time(time_current)\n",
    "    for time_existing, linkinfo_existing in e_cpy.items():  \n",
    "\n",
    "        l_e_t = linkinfo_existing.copy()\n",
    "        # iterate through all the current links at a particular time\n",
    "        for existing_vehicle_pair, existing_features in l_e_t.items():\n",
    "            link_break = True \n",
    "            \n",
    "            for current_vehicle_pair, current_features in linkinfo_current.items():\n",
    "                \n",
    "                if sorted(existing_vehicle_pair) == sorted(current_vehicle_pair):\n",
    "                    link_break = False\n",
    "                    break # know that this existing_vehicle pair is still in contact, move on to check the next\n",
    "            \n",
    "            if link_break == True:                   \n",
    "                # if it doesn't equal to any of the current_vehicle_pair, then we know that the contact ends here\n",
    "                # compute link_duration\n",
    "                link_duration = time_current - time_existing \n",
    "                \n",
    "                # store all info(existing_vehicle_pair, existing_features, link_duration) to a new np array                        \n",
    "                new_data = list(existing_vehicle_pair)\n",
    "                existing_features.append(link_duration)\n",
    "                new_data.extend(existing_features)\n",
    "                #then append this numpy array to the 'final_output' numpy array\n",
    "                contact_info.append(new_data)\n",
    "\n",
    "                # a brief view of the data\n",
    "                #print(existing_vehicle_pair, existing_time, link_duration)\n",
    "                                \n",
    "                # remove the link that ends at this time from 'existing_links'\n",
    "                existing_links.get(time_existing).pop(existing_vehicle_pair)\n",
    "                leng = len(existing_links.get(time_existing).keys())\n",
    "                if(leng == 0):\n",
    "                    existing_links.pop(time_existing)\n",
    "                \n",
    "    \n",
    "    ###############################################################################################################\n",
    "    #iterate through current links to see if it's a new link.\n",
    "    \n",
    "    e_cpy = existing_links.copy() \n",
    "    \n",
    "    for current_vehicle_pair, current_features in linkinfo_current.items(): \n",
    "               \n",
    "        #\n",
    "        if len(e_cpy.keys()) == 0: # if there's no existing link, then add all current links to existing_links\n",
    "            existing_links.update( {time_current:linkinfo_current} )\n",
    "            continue\n",
    "        \n",
    "        is_new = True # if it's a new link, set the default value as True\n",
    "        \n",
    "        for time_existing, linkinfo_existing in e_cpy.items(): \n",
    "            \n",
    "            l_e_t = linkinfo_existing.copy() \n",
    "                        \n",
    "            for existing_vehicle_pair, existing_features in l_e_t.items():\n",
    "                if sorted(current_vehicle_pair) == sorted(existing_vehicle_pair):\n",
    "                    is_new = False\n",
    "                    break # know that this current_vehicle_pair is already in contact, move on to check the next\n",
    "                \n",
    "        # if it doesn't equal to any of the existing_vehicle pair, then we know that the it's a new link \n",
    "        # add this to the existing_links            \n",
    "        if is_new == True:\n",
    "            new_link = {current_vehicle_pair: current_features}\n",
    "            existing_links.update( {time_current:new_link} )\n",
    "            \n",
    "#convert the list to a numpy array        \n",
    "output_array = np.asarray(contact_info)    \n",
    "\n",
    "# convert the numpy array to a csv file.\n",
    "what_we_want = np.savetxt(\"ouput_t.csv\", output_array, delimiter=\",\",fmt = \"%s\")\n",
    "\n",
    "# after this, we still need to further process the csv file a little bit to get the right format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
